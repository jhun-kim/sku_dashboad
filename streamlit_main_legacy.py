import streamlit as st
import pandas as pd
from collections import deque
from datetime import datetime
import hashlib  # ì¤‘ë³µ ë°©ì§€ìš© í•´ì‹œ ìƒì„±
import os

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ìŠ¤íƒ€ì¼ ---
st.set_page_config(layout="wide", page_title="AI Tracking System 2026")
st.markdown("""
    <style>
    [data-testid="stSidebar"] { min-width: 320px; }
    .stMetric { background-color: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #dee2e6; }
    </style>
    """, unsafe_allow_html=True)


# --- 2. í•µì‹¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def generate_row_hash(row):
    """ë°ì´í„° í–‰ì˜ ê³ ìœ  í•´ì‹œê°’ ìƒì„± (ë‚ ì§œ, í’ˆëª©ëª…, êµ¬ë¶„, ìˆ˜ëŸ‰, ë‹¨ê°€ ê¸°ì¤€)"""
    payload = f"{row['ë‚ ì§œ']}{row['í’ˆëª©ëª…']}{row['êµ¬ë¶„']}{row['ìˆ˜ëŸ‰']}{row['ë‹¨ê°€']}"
    return hashlib.md5(payload.encode()).hexdigest()


def initialize_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë“œ"""
    if 'history' not in st.session_state:
        file_path = 'inventory_10k_data.xlsx'
        if os.path.exists(file_path):
            df = pd.read_excel(file_path)
            df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
            # ê¸°ì¡´ ë°ì´í„°ì— ì„¸ë¶€êµ¬ë¶„ ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ í• ë‹¹
            if 'ì„¸ë¶€êµ¬ë¶„' not in df.columns:
                df['ì„¸ë¶€êµ¬ë¶„'] = df['êµ¬ë¶„'].map({'ì…ê³ ': 'ë§¤ì…', 'ì¶œê³ ': 'ë§¤ì¶œ'})
            if 'hash' not in df.columns:
                df['hash'] = df.apply(generate_row_hash, axis=1)
            st.session_state.history = df.sort_values(by='ë‚ ì§œ').reset_index(drop=True)
        else:
            st.session_state.history = pd.DataFrame(columns=['ë‚ ì§œ', 'í’ˆëª©ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€êµ¬ë¶„', 'ìˆ˜ëŸ‰', 'ë‹¨ê°€', 'ë§¤ì¶œì›ê°€', 'ë¹„ê³ ', 'hash'])

    if 'inventory_queues' not in st.session_state:
        reconstruct_queues()
    if 'latest_fifo_detail' not in st.session_state:
        st.session_state.latest_fifo_detail = pd.DataFrame()


def reconstruct_queues():
    """ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ìˆœíšŒí•˜ì—¬ FIFO í ë³µì›"""
    items = st.session_state.history['í’ˆëª©ëª…'].unique()
    queues = {item: deque() for item in items}
    # ë‚ ì§œ ìˆœì„œëŒ€ë¡œ ë‹¤ì‹œ ê³„ì‚°í•˜ì—¬ ë¬´ê²°ì„± ë³´ì¥
    sorted_hist = st.session_state.history.sort_values('ë‚ ì§œ')
    for _, row in sorted_hist.iterrows():
        item = row['í’ˆëª©ëª…']
        if row['êµ¬ë¶„'] == 'ì…ê³ ':
            queues[item].append({'date': row['ë‚ ì§œ'], 'qty': row['ìˆ˜ëŸ‰'], 'price': row['ë‹¨ê°€']})
        elif row['êµ¬ë¶„'] == 'ì¶œê³ ':
            qty = row['ìˆ˜ëŸ‰']
            q = queues.get(item, deque())
            while qty > 0 and q:
                if q[0]['qty'] <= qty:
                    qty -= q[0]['qty']
                    q.popleft()
                else:
                    q[0]['qty'] -= qty
                    qty = 0
    st.session_state.inventory_queues = queues


# --- 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ---

# --- [í•µì‹¬ ë¡œì§] FIFO ì—”ì§„ ë° ë¹„ê³  ê¸°ë¡ ê¸°ëŠ¥ ---
def process_transaction(date, item, action, sub_type, qty, price=0, row_hash=None):
    """
    ë‹¨ì¼ íŠ¸ëœì­ì…˜ì„ ì²˜ë¦¬í•˜ë©°, ì¶œê³  ì‹œ ì–´ë–¤ ë°°ì¹˜ì˜ ì¬ê³ ê°€ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ ë¹„ê³ ì— ê¸°ë¡í•¨
    """
    date = pd.to_datetime(date)
    if not row_hash:
        row_hash = hashlib.md5(f"{date}{item}{action}{sub_type}{qty}{price}".encode()).hexdigest()

    new_record = {
        'ë‚ ì§œ': date, 'í’ˆëª©ëª…': item, 'êµ¬ë¶„': action, 'ì„¸ë¶€êµ¬ë¶„': sub_type,
        'ìˆ˜ëŸ‰': qty, 'ë‹¨ê°€': price if action == 'ì…ê³ ' else 0,
        'ë§¤ì¶œì›ê°€': 0, 'ë¹„ê³ ': '', 'hash': row_hash
    }

    if item not in st.session_state.inventory_queues:
        st.session_state.inventory_queues[item] = deque()
    queue = st.session_state.inventory_queues[item]

    if action == "ì…ê³ ":
        queue.append({'date': date, 'qty': qty, 'price': price})
        new_record['ë¹„ê³ '] = f"[{sub_type}] {qty}ê°œ ì…ê³  ì™„ë£Œ"

    elif action == "ì¶œê³ ":
        remaining = qty
        total_cogs = 0
        details = []  # ë¹„ê³  ì‘ì„±ì„ ìœ„í•œ ìƒì„¸ ë‚´ì—­ ë¦¬ìŠ¤íŠ¸

        while remaining > 0 and queue:
            batch = queue[0]
            batch_date_str = batch['date'].strftime('%Y-%m-%d')

            if batch['qty'] <= remaining:
                # ë°°ì¹˜ ì™„ì „ ì†Œì§„
                use_qty = batch['qty']
                cost = use_qty * batch['price']
                total_cogs += cost
                remaining -= use_qty
                details.append(f"{batch_date_str}ë¶„ {use_qty}ê°œ(@{batch['price']:,}ì›)")
                queue.popleft()
            else:
                # ë°°ì¹˜ ë¶€ë¶„ ì†Œì§„
                use_qty = remaining
                cost = use_qty * batch['price']
                total_cogs += cost
                batch['qty'] -= use_qty
                remaining = 0
                details.append(f"{batch_date_str}ë¶„ {use_qty}ê°œ(@{batch['price']:,}ì›)")

        new_record['ë§¤ì¶œì›ê°€'] = total_cogs

        # --- [ìˆ˜ì • í¬ì¸íŠ¸] ë¹„ê³ ë€ì— ìƒì„¸ ì¶œê³  ë‚´ì—­ ì‘ì„± ---
        if remaining == 0:
            detail_str = ", ".join(details)
            new_record['ë¹„ê³ '] = f"[{sub_type}] ì¶œê³ ì™„ë£Œ ({detail_str})"
        else:
            detail_str = ", ".join(details) if details else "ì¬ê³  ì—†ìŒ"
            new_record['ë¹„ê³ '] = f"âš ï¸ì¬ê³ ë¶€ì¡± (ì¼ë¶€ì¶œê³ : {detail_str}, ë¯¸ì¶œê³ : {remaining}ê°œ)"

    # íˆìŠ¤í† ë¦¬ì— ê¸°ë¡ ì¶”ê°€
    st.session_state.history = pd.concat([st.session_state.history, pd.DataFrame([new_record])], ignore_index=True)


# --- 4. ì—‘ì…€ ì—…ë¡œë“œ ì²˜ë¦¬ ---

def handle_excel_upload(uploaded_file):
    try:
        df = pd.read_excel(uploaded_file)
        required = ['ë‚ ì§œ', 'í’ˆëª©ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€êµ¬ë¶„', 'ìˆ˜ëŸ‰', 'ë‹¨ê°€']
        if not all(c in df.columns for c in required):
            st.error(f"ì–‘ì‹ ì˜¤ë¥˜! í•„ìˆ˜ ì»¬ëŸ¼: {required}")
            return

        df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
        df['hash'] = df.apply(generate_row_hash, axis=1)

        existing_hashes = set(st.session_state.history['hash'].tolist())
        new_data = df[~df['hash'].isin(existing_hashes)].copy()

        if new_data.empty:
            st.warning("ì¶”ê°€í•  ì‹ ê·œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        new_data = new_data.sort_values('ë‚ ì§œ')
        with st.status("ë°ì´í„° ë¶„ì„ ì¤‘...") as status:
            for _, row in new_data.iterrows():
                process_transaction(row['ë‚ ì§œ'], row['í’ˆëª©ëª…'], row['êµ¬ë¶„'], row['ì„¸ë¶€êµ¬ë¶„'], row['ìˆ˜ëŸ‰'], row['ë‹¨ê°€'], row['hash'])
            status.update(label="ë°˜ì˜ ì™„ë£Œ!", state="complete")

        st.session_state.history = st.session_state.history.sort_values('ë‚ ì§œ').reset_index(drop=True)
        st.rerun()
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

# --- [ì¶”ê°€] 3-1. íŒë§¤ ì§€í‘œ ê³„ì‚° ë¡œì§ ---
def calculate_sales_metrics(item_name):
    """
    íŠ¹ì • í’ˆëª©ì˜ 1ë…„ í‰ê·  ë° ìµœê·¼ 3ê°œì›” í‰ê·  íŒë§¤ëŸ‰ì„ ê³„ì‚°
    """
    history = st.session_state.history
    now = datetime.now()

    # í•´ë‹¹ í’ˆëª©ì˜ 'ì¶œê³ ' ê¸°ë¡ë§Œ í•„í„°ë§
    sales_df = history[(history['í’ˆëª©ëª…'] == item_name) & (history['êµ¬ë¶„'] == 'ì¶œê³ ')].copy()

    if sales_df.empty:
        return 0, 0, 0

    # ë‚ ì§œ í•„í„°ë§ì„ ìœ„í•œ ê¸°ì¤€ ì„¤ì •
    one_year_ago = now - pd.Timedelta(days=365)
    three_months_ago = now - pd.Timedelta(days=90)

    # 1. 1ë…„ ê¸°ì¤€ ì›”í‰ê·  íŒë§¤ëŸ‰ (ìµœê·¼ 365ì¼ íŒë§¤ëŸ‰ / 12)
    last_year_sales = sales_df[sales_df['ë‚ ì§œ'] >= one_year_ago]['ìˆ˜ëŸ‰'].sum()
    avg_12m = last_year_sales / 12

    # 2. ìµœê·¼ 3ê°œì›” ì›”í‰ê·  íŒë§¤ëŸ‰ (ìµœê·¼ 90ì¼ íŒë§¤ëŸ‰ / 3)
    last_3m_sales = sales_df[sales_df['ë‚ ì§œ'] >= three_months_ago]['ìˆ˜ëŸ‰'].sum()
    avg_3m = last_3m_sales / 3

    # 3. í˜„ì¬ê³ 
    current_stock = sum(b['qty'] for b in st.session_state.inventory_queues.get(item_name, []))

    return current_stock, avg_12m, avg_3m


# --- [ì¶”ê°€] 3-2. ì‹¤ì‹œê°„ ì¬ê³  ì§‘ê³„ í•¨ìˆ˜ ---
def get_inventory_summary():
    """í˜„ì¬ FIFO íì— ë‚¨ì€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í’ˆëª©ë³„ ìš”ì•½ ìƒì„±"""
    summary_data = []

    for item, queue in st.session_state.inventory_queues.items():
        total_qty = sum(batch['qty'] for batch in queue)
        total_value = sum(batch['qty'] * batch['price'] for batch in queue)
        avg_price = total_value / total_qty if total_qty > 0 else 0

        if total_qty >= 0:  # ì¬ê³ ê°€ 0ì¸ í’ˆëª©ë„ í¬í•¨ (í•„ìš”ì‹œ > 0ìœ¼ë¡œ ë³€ê²½)
            summary_data.append({
                "í’ˆëª©ëª…": item,
                "í˜„ì¬ê³  ìˆ˜ëŸ‰": total_qty,
                "í‰ê·  ë§¤ì…ë‹¨ê°€": avg_price,
                "ì¬ê³  ìì‚°ê¸ˆì•¡": total_value
            })

    return pd.DataFrame(summary_data)


# --- [ì¶”ê°€] 3-3. ì°¨ê¸° ì¶œê³  ì˜ˆì • ì¬ê³ (FIFO Queue) ë¶„ì„ í•¨ìˆ˜ ---
def get_next_out_schedule():
    """ê° í’ˆëª©ë³„ë¡œ FIFO ê¸°ì¤€ ê°€ì¥ ë¨¼ì € ì¶œê³ ë  ì¬ê³  ë‚ ì§œì™€ ìˆ˜ëŸ‰ ë¶„ì„"""
    schedule_data = []

    for item, queue in st.session_state.inventory_queues.items():
        if not queue:
            continue

        # 1ìˆœìœ„ (ê°€ì¥ ì˜¤ë˜ëœ ì¬ê³ )
        first_batch = queue[0]

        # 2ìˆœìœ„ (ìˆì„ ê²½ìš°ì—ë§Œ)
        second_batch = queue[1] if len(queue) > 1 else None

        schedule_data.append({
            "í’ˆëª©ëª…": item,
            "1ìˆœìœ„ ì¶œê³ ì˜ˆì •ì¼": first_batch['date'],
            "1ìˆœìœ„ ëŒ€ê¸°ìˆ˜ëŸ‰": first_batch['qty'],
            "1ìˆœìœ„ ë‹¨ê°€": first_batch['price'],
            "2ìˆœìœ„ ì¶œê³ ì˜ˆì •ì¼": second_batch['date'] if second_batch else None,
            "2ìˆœìœ„ ëŒ€ê¸°ìˆ˜ëŸ‰": second_batch['qty'],
            "ì „ì²´ ì¬ê³ ì¸µ ìˆ˜": len(queue)
        })

    return pd.DataFrame(schedule_data)

# --- 4. ë©”ì¸ UI êµ¬ì„± ---
initialize_state()

# [ì‚¬ì´ë“œë°” ì˜ì—­]
with st.sidebar:
    st.title("ğŸ“¦ AI ì¬ê³  ê´€ë¦¬")
    app_mode = st.radio("ë©”ë‰´ ì„ íƒ", ["ë°ì´í„° ì¼ê´„ ì—…ë¡œë“œ", "ë°ì´í„° ë¶„ì„/íŠ¸ë˜í‚¹"])
    st.divider()
    # í…œí”Œë¦¿ì—ë„ ì„¸ë¶€êµ¬ë¶„ ì¶”ê°€
    template = pd.DataFrame(columns=['ë‚ ì§œ', 'í’ˆëª©ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€êµ¬ë¶„', 'ìˆ˜ëŸ‰', 'ë‹¨ê°€'])
    st.download_button("ğŸ“¥ ì—…ë¡œë“œ ì–‘ì‹ ë‹¤ìš´ë¡œë“œ", data=template.to_csv(index=False).encode('utf-8-sig'),
                       file_name="template_v2.csv")

if app_mode == "ë°ì´í„° ì¼ê´„ ì—…ë¡œë“œ":
    st.title("ğŸ“¥ ëŒ€ëŸ‰ ì…ì¶œê³  ì—…ë¡œë“œ ë° ì´ë ¥")

    with st.expander("ğŸ“ ì‹ ê·œ ë°ì´í„° ì—…ë¡œë“œ"):
        uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=['xlsx'])
        if uploaded_file and st.button("ğŸš€ ë°ì´í„° ë°˜ì˜í•˜ê¸°", use_container_width=True):
            handle_excel_upload(uploaded_file)

    st.divider()
    st.subheader("ğŸ” ë°ì´í„° í•„í„°ë§ (ì„¸ë¶€êµ¬ë¶„ í¬í•¨)")
    df_display = st.session_state.history.copy()

    f1, f2, f3 = st.columns([1.5, 1.5, 2])
    with f1:
        selected_items = st.multiselect("ğŸ“¦ í’ˆëª© ì„ íƒ", sorted(df_display['í’ˆëª©ëª…'].unique()))
    with f2:
        # ì„¸ë¶€êµ¬ë¶„ í•„í„° ì¶”ê°€
        all_subtypes = sorted(df_display['ì„¸ë¶€êµ¬ë¶„'].unique())
        selected_subs = st.multiselect("ğŸ“‚ ì„¸ë¶€êµ¬ë¶„ ì„ íƒ", all_subtypes, default=all_subtypes)
    with f3:
        if not df_display.empty:
            date_range = st.date_input("ğŸ“… ê¸°ê°„", value=(df_display['ë‚ ì§œ'].min().date(), df_display['ë‚ ì§œ'].max().date()))
        else:
            date_range = []

    # í•„í„° ì ìš©
    if selected_items: df_display = df_display[df_display['í’ˆëª©ëª…'].isin(selected_items)]
    df_display = df_display[df_display['ì„¸ë¶€êµ¬ë¶„'].isin(selected_subs)]
    if len(date_range) == 2:
        df_display = df_display[
            (df_display['ë‚ ì§œ'].dt.date >= date_range[0]) & (df_display['ë‚ ì§œ'].dt.date <= date_range[1])]

    st.dataframe(
        df_display.sort_values('ë‚ ì§œ', ascending=False),
        use_container_width=True,
        hide_index=True,
        column_config={
            "ë‚ ì§œ": st.column_config.DatetimeColumn("ë‚ ì§œ", format="YYYY-MM-DD"),
            "êµ¬ë¶„": st.column_config.TextColumn("ëŒ€ë¶„ë¥˜"),
            "ì„¸ë¶€êµ¬ë¶„": st.column_config.TextColumn("ì…ì¶œê³  ì‚¬ìœ "),
            "ìˆ˜ëŸ‰": st.column_config.NumberColumn("ìˆ˜ëŸ‰", format="%d ê°œ"),
            "ë‹¨ê°€": st.column_config.NumberColumn("ë‹¨ê°€", format="â‚© %d"),
            "ë§¤ì¶œì›ê°€": st.column_config.NumberColumn("ì›ê°€(FIFO)", format="â‚© %d"),
            "hash": None
        }
    )

    # [2] ì‹¤ì‹œê°„ ì¬ê³  ìš”ì•½ ì„¹ì…˜ (ì‹ ê·œ ì¶”ê°€)
    st.subheader("ğŸ“¦ í˜„ì¬ê³  ìš”ì•½ í˜„í™© (í’ˆëª©ë³„)")
    inv_summary_df = get_inventory_summary()


    if not inv_summary_df.empty:
        # ê°€ë…ì„±ì„ ìœ„í•´ 3ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ì£¼ìš” ì§€í‘œ í‘œì‹œ
        tot_items = len(inv_summary_df)
        tot_qty = inv_summary_df['í˜„ì¬ê³  ìˆ˜ëŸ‰'].sum()
        tot_val = inv_summary_df['ì¬ê³  ìì‚°ê¸ˆì•¡'].sum()

        m1, m2, m3 = st.columns(3)
        m1.metric("ê´€ë¦¬ í’ˆëª© ìˆ˜", f"{tot_items} ì¢…")
        m2.metric("ì „ì²´ ì¬ê³  ìˆ˜ëŸ‰", f"{tot_qty:,} ê°œ")
        m3.metric("ì „ì²´ ìì‚° ê°€ì¹˜", f"â‚© {tot_val:,.0f}")

        # ìš”ì•½ í…Œì´ë¸” ì¶œë ¥
        st.dataframe(
            inv_summary_df.sort_values("ì¬ê³  ìì‚°ê¸ˆì•¡", ascending=False),
            use_container_width=True,
            hide_index=True,
            column_config={
                "í˜„ì¬ê³  ìˆ˜ëŸ‰": st.column_config.NumberColumn(format="%d ê°œ"),
                "í‰ê·  ë§¤ì…ë‹¨ê°€": st.column_config.NumberColumn(format="â‚© %d"),
                "ì¬ê³  ìì‚°ê¸ˆì•¡": st.column_config.NumberColumn(format="â‚© %d"),
            }
        )
    else:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

    st.divider()
    # [ì‹ ê·œ] ì°¨ê¸° ì¶œê³  ì˜ˆì • ìƒì„¸ í‘œ
    st.subheader("ğŸ“‹ ì¶œê³  ìš°ì„ ìˆœìœ„ í˜„í™© (FIFO Queue)")
    st.caption("í˜„ì¬ ë³´ìœ  ì¬ê³  ì¤‘ ë‚ ì§œê°€ ê°€ì¥ ì˜¤ë˜ë˜ì–´ 'ë‹¤ìŒ ì¶œê³  ì‹œ' ê°€ì¥ ë¨¼ì € ì°¨ê°ë  ë°ì´í„°ì…ë‹ˆë‹¤.")

    next_out_df = get_next_out_schedule()

    if not next_out_df.empty:
        st.dataframe(
            next_out_df.sort_values("1ìˆœìœ„ ì¶œê³ ì˜ˆì •ì¼"),  # ì˜¤ë˜ëœ ìˆœìœ¼ë¡œ ì •ë ¬
            use_container_width=True,
            hide_index=True,
            column_config={
                "1ìˆœìœ„ ì¶œê³ ì˜ˆì •ì¼": st.column_config.DatetimeColumn("ê°€ì¥ ì˜¤ë˜ëœ ì…ê³ ì¼", format="YYYY-MM-DD"),
                "1ìˆœìœ„ ëŒ€ê¸°ìˆ˜ëŸ‰": st.column_config.NumberColumn("í˜„ ì¬ê³ (1ìˆœìœ„)", format="%d ê°œ"),
                "1ìˆœìœ„ ë‹¨ê°€": st.column_config.NumberColumn("ì·¨ë“ë‹¨ê°€", format="â‚© %d"),
                "2ìˆœìœ„ ì¶œê³ ì˜ˆì •ì¼": st.column_config.DatetimeColumn("ì°¨ìˆœìœ„ ì…ê³ ì¼", format="YYYY-MM-DD"),
                "2ìˆœìœ„ ëŒ€ê¸°ìˆ˜ëŸ‰": st.column_config.NumberColumn("ì°¨ìˆœìœ„ ì¬ê³ (2ìˆœìœ„)", format="%d ê°œ"),
                "ì „ì²´ ì¬ê³ ì¸µ ìˆ˜": st.column_config.NumberColumn("ëˆ„ì  ì…ê³  íšŸìˆ˜", format="%d ì¸µ")
            }
        )

    else:
        st.info("ì¶œê³  ëŒ€ê¸° ì¤‘ì¸ ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
elif app_mode == "ë°ì´í„° ë¶„ì„/íŠ¸ë˜í‚¹":
    st.title("ğŸ” ìˆ˜ì… ì ì •ì¬ê³  ê²€í†  ëŒ€ì‹œë³´ë“œ")
    st.info("ìˆ˜ì… ë¦¬ë“œ íƒ€ì„ì„ ê³ ë ¤í•˜ì—¬ í’ˆëª©ë³„ ë°œì£¼ í•„ìš”ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. (ê¸°ì¤€ì¼: 2026-01-14)")

    # 1. í’ˆëª© ì„ íƒ (90ì—¬ ê°œì˜ ìˆ˜ì… í’ˆëª© ëŒ€ì‘)
    item_list = sorted(st.session_state.history['í’ˆëª©ëª…'].unique())
    if not item_list:
        st.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì…ê³  ê¸°ë¡ì„ ìƒì„±í•˜ì„¸ìš”.")
    else:
        selected_item = st.selectbox("ğŸ“Š ë¶„ì„í•  í’ˆëª©ì„ ì„ íƒí•˜ì„¸ìš”", item_list)

        # ë°ì´í„° ê³„ì‚°
        curr_stock, m12_avg, m3_avg = calculate_sales_metrics(selected_item)

        # 2. í•µì‹¬ ì§€í‘œ ë ˆì´ì•„ì›ƒ (Metrics)
        st.divider()
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("í˜„ì¬ ì°½ê³  ì¬ê³ ", f"{curr_stock:,} ê°œ")

        with col2:
            st.metric("1ë…„ í‰ê·  íŒë§¤ (ì›”)", f"{int(m12_avg)} ê°œ")

        with col3:
            # ìµœê·¼ 3ê°œì›” íŒë§¤ ì¶”ì„¸ ê³„ì‚° (ì „ë…„ í‰ê·  ëŒ€ë¹„)
            trend = m3_avg - m12_avg
            st.metric("ìµœê·¼ 3ê°œì›” íŒë§¤ (ì›”)", f"{int(m3_avg)} ê°œ", delta=f"{trend:,.1f} (ì¶”ì„¸)")

        with col4:
            # ì¬ê³  ë³´ìœ  ê°œì›” ìˆ˜ (í˜„ì¬ê³  / ìµœê·¼ 3ê°œì›” íŒë§¤ëŸ‰)
            stock_months = curr_stock / m3_avg if m3_avg > 0 else 0
            st.metric("ì¬ê³  ì†Œì§„ ì˜ˆì • (ê°œì›”)", f"{stock_months:.1f} ê°œì›”ë¶„")

        # 3. ë°œì£¼ ì œì–¸ ì‹œê°í™”
        st.subheader("ğŸ’¡ AI ë°œì£¼ íŒë‹¨ ê°€ì´ë“œ")

        # ê°„ë‹¨í•œ ë¡œì§ ì˜ˆì‹œ: ì¬ê³ ê°€ 3ê°œì›” íŒë§¤ëŸ‰ë³´ë‹¤ ì ìœ¼ë©´ ë°œì£¼ ê²€í† 
        lead_time_buffer = 2.0  # ìˆ˜ì… ë¦¬ë“œíƒ€ì„ 2ê°œì›” ê°€ì •
        if stock_months < lead_time_buffer:
            st.error(f"âš ï¸ **ë°œì£¼ ê²€í†  í•„ìš”**: í˜„ì¬ ì¬ê³ ê°€ ë¦¬ë“œíƒ€ì„({lead_time_buffer}ê°œì›”) ëŒ€ë¹„ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        elif stock_months < lead_time_buffer + 1:
            st.warning("ğŸŸ¡ **ê´€ì°° í•„ìš”**: ì¬ê³  ìˆ˜ì¤€ì´ ì ì •ì„  í•˜ë‹¨ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.success("âœ… **ì¬ê³  ì¶©ë¶„**: í˜„ì¬ ì•ˆì •ì ì¸ ì¬ê³  ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

        # 4. ìƒì„¸ íŒë§¤ ì°¨íŠ¸ (Optional)
        st.subheader("ğŸ“ˆ ì›”ë³„ ì¶œê³  íŠ¸ë Œë“œ")
        item_history = st.session_state.history[
            (st.session_state.history['í’ˆëª©ëª…'] == selected_item) &
            (st.session_state.history['êµ¬ë¶„'] == 'ì¶œê³ ')
            ].set_index('ë‚ ì§œ')

        if not item_history.empty:
            # ì›”ë³„ë¡œ ë¦¬ìƒ˜í”Œë§í•˜ì—¬ í•©ê³„ ê³„ì‚°
            monthly_sales = item_history['ìˆ˜ëŸ‰'].resample('ME').sum()
            monthly_growth = monthly_sales.pct_change() * 100
            st.metric("ì „ì›” ëŒ€ë¹„ ì„±ì¥ë¥ ", f"{monthly_sales.iloc[-1]:,.0f} ê°œ", delta=f"{monthly_growth.iloc[-2]:.1f}%")
            st.bar_chart(monthly_sales)
        else:
            st.write("íŒë§¤ ê¸°ë¡ì´ ì—†ì–´ ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")